{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib as ta\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "def get_score(model, x_train=0, x_test=0):\n",
    "    if not x_train or not x_test:\n",
    "        x_train = X_train\n",
    "        x_test = X_test\n",
    "    y_pred = model.predict(x_test)\n",
    "    print('train: {}'.format(model.score(x_train, y_train) * 100))\n",
    "    print('test: {}'.format(model.score(x_test, y_test) * 100))\n",
    "    print('accuracy score: {}'.format(accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "params_l1 = {\n",
    "    'log__penalty': ['l1'],\n",
    "    'log__C': np.logspace(-4, 4, 20),\n",
    "    'log__tol': [0.00001, 0.0001, 0.001, 0.01, 0.10],\n",
    "    'log__class_weight': [None, 'balanced'],\n",
    "    'log__solver': ['saga'],\n",
    "    'log__multi_class': ['ovr', 'multinomial', 'auto']\n",
    "}\n",
    "params_l2 = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': np.logspace(-4, 4, 20),\n",
    "    'tol': [0.00001, 0.0001, 0.001, 0.01, 0.10],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'sag'],\n",
    "    'multi_class': ['ovr', 'multinomial', 'auto']\n",
    "}\n",
    "best_params = knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data3_H1.csv', parse_dates=['Datetime'], index_col='Datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Target', axis=1).values\n",
    "y = df.Target.values\n",
    "\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "half_split = int(len(X_tmp) / 2)\n",
    "X_test = X_tmp[:half_split]\n",
    "X_final = X_tmp[half_split:]\n",
    "y_test = y_tmp[:half_split]\n",
    "y_final = y_tmp[half_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_final = scaler.transform(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures()\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.transform(X_test)\n",
    "X_final = poly.transform(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67713, 351)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14510, 351)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/python3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 53.864102904907476\n",
      "test: 52.370778773259815\n",
      "accuracy score: 52.370778773259815\n"
     ]
    }
   ],
   "source": [
    "get_score(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1800 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min\n",
      "/anaconda2/envs/python3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 41.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 62.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 167.7min\n"
     ]
    }
   ],
   "source": [
    "log_cv2 = GridSearchCV(LogisticRegression(), params_l2, cv=3, verbose=True, n_jobs=-1)\n",
    "log_cv2.fit(X_train, y_train)\n",
    "print('best score: {}'.format(log_cv2.best_score_ * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    LogisticRegression(**best_params),\n",
    "    n_estimators=1000,\n",
    "    algorithm=\"SAMME.R\",\n",
    "    learning_rate=0.01\n",
    ")\n",
    "ada_clf.fit(X_train, y_train)\n",
    "get_score(ads_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_log = BaggingClassifier(\n",
    "    LogisticRegression(**best_params),\n",
    "    n_estimators=1000,\n",
    "    max_samples=500,\n",
    "    bootstrap=True\n",
    ")\n",
    "bag_log.fit(X_train, y_train)\n",
    "get_score(bag_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
